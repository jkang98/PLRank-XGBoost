[I 2023-11-24 20:21:13,640] A new study created in memory with name: no-name-5f5c16f8-4ba5-4d15-ba89-aea7e74c673f
[I 2023-11-24 20:57:27,379] Trial 0 finished with value: 0.6896934972515663 and parameters: {'learning_rate': 1.222763640777128e-08, 'max_depth': 3, 'min_child_weight': 5, 'gamma': 0.00010285748625554399, 'lambda': 2.5677657549838753e-07, 'alpha': 0.19330218749849726}. Best is trial 0 with value: 0.6896934972515663.
/home/jkang1/plrank3.py:106: RuntimeWarning: divide by zero encountered in divide
  cumsum_weight_denom = np.cumsum(rank_weights[:cutoff] / denom_per_rank, axis=1)
/home/jkang1/plrank3.py:108: RuntimeWarning: divide by zero encountered in divide
  cumsum_reward_denom = np.cumsum(cumsum_labels / denom_per_rank, axis=1)
/home/jkang1/plrank3.py:122: RuntimeWarning: invalid value encountered in multiply
  labels[cutoff_sampled_rankings]
/home/jkang1/plrank3.py:126: RuntimeWarning: invalid value encountered in multiply
  sampled_following_reward = exp_scores[cutoff_sampled_rankings] * cumsum_reward_denom
/home/jkang1/plrank3.py:166: RuntimeWarning: divide by zero encountered in divide
  * np.cumsum(1 / denom_per_rank[:, :-1], axis=1)
/home/jkang1/plrank3.py:165: RuntimeWarning: invalid value encountered in multiply
  - exp_scores[cutoff_sampled_rankings[:, :-1]]
/home/jkang1/plrank3.py:171: RuntimeWarning: divide by zero encountered in divide
  cumsum_denom = np.cumsum(1 / denom_per_rank, axis=1)
/home/jkang1/plrank3.py:172: RuntimeWarning: invalid value encountered in multiply
  sum_prob_per_doc = exp_scores * cumsum_denom[:, -1, None]
/home/jkang1/plrank3.py:174: RuntimeWarning: invalid value encountered in multiply
  exp_scores[cutoff_sampled_rankings] * cumsum_denom
/home/jkang1/plrank3.py:182: RuntimeWarning: divide by zero encountered in divide
  cumsum_weight_denom = np.cumsum(rank_weights[:cutoff] / denom_per_rank, axis=1)
/home/jkang1/plrank3.py:184: RuntimeWarning: divide by zero encountered in divide
  cumsum_reward_denom = np.cumsum(cumsum_labels / denom_per_rank, axis=1)
/home/jkang1/plrank3.py:197: RuntimeWarning: invalid value encountered in multiply
  labels[cutoff_sampled_rankings]
/home/jkang1/plrank3.py:201: RuntimeWarning: invalid value encountered in multiply
  sampled_following_reward = exp_scores[cutoff_sampled_rankings] * cumsum_reward_denom
/home/jkang1/plrank3.py:208: RuntimeWarning: divide by zero encountered in divide
  rank_weights[:cutoff] / denom_per_rank ** 2, axis=1
/home/jkang1/plrank3.py:211: RuntimeWarning: divide by zero encountered in divide
  cumsum_reward_denom_square = np.cumsum(cumsum_labels / denom_per_rank ** 2, axis=1)
/home/jkang1/plrank3.py:224: RuntimeWarning: invalid value encountered in multiply
  labels[cutoff_sampled_rankings]
/home/jkang1/plrank3.py:229: RuntimeWarning: invalid value encountered in multiply
  exp_scores[cutoff_sampled_rankings] ** 2 * cumsum_reward_denom_square
/home/jkang1/plrank3.py:108: RuntimeWarning: invalid value encountered in divide
  cumsum_reward_denom = np.cumsum(cumsum_labels / denom_per_rank, axis=1)
/home/jkang1/plrank3.py:184: RuntimeWarning: invalid value encountered in divide
  cumsum_reward_denom = np.cumsum(cumsum_labels / denom_per_rank, axis=1)
/home/jkang1/plrank3.py:211: RuntimeWarning: invalid value encountered in divide
  cumsum_reward_denom_square = np.cumsum(cumsum_labels / denom_per_rank ** 2, axis=1)
/home/jkang1/plrank3.py:112: RuntimeWarning: invalid value encountered in multiply
  second_part = -exp_scores[None, :] * cumsum_reward_denom[:, -1, None]
/home/jkang1/plrank3.py:114: RuntimeWarning: invalid value encountered in multiply
  labels[relevant_docs][None, :]
/home/jkang1/plrank3.py:113: RuntimeWarning: invalid value encountered in add
  second_part[:, relevant_docs] += (
/home/jkang1/plrank3.py:187: RuntimeWarning: invalid value encountered in multiply
  second_part = -exp_scores[None, :] * cumsum_reward_denom[:, -1, None]
/home/jkang1/plrank3.py:189: RuntimeWarning: invalid value encountered in multiply
  labels[relevant_docs][None, :]
/home/jkang1/plrank3.py:188: RuntimeWarning: invalid value encountered in add
  second_part[:, relevant_docs] += (
/home/jkang1/plrank3.py:214: RuntimeWarning: invalid value encountered in multiply
  third_part = -exp_scores[None, :] ** 2 * cumsum_reward_denom_square[:, -1, None]
/home/jkang1/plrank3.py:216: RuntimeWarning: invalid value encountered in multiply
  labels[relevant_docs][None, :]
/home/jkang1/plrank3.py:215: RuntimeWarning: invalid value encountered in add
  third_part[:, relevant_docs] += (
[I 2023-11-24 22:11:01,184] Trial 1 finished with value: 0.7636608358426105 and parameters: {'learning_rate': 0.37660378459187677, 'max_depth': 2, 'min_child_weight': 8, 'gamma': 1.1405518722450977e-06, 'lambda': 1.0417421997120932e-06, 'alpha': 1.4974494913988635e-07}. Best is trial 1 with value: 0.7636608358426105.
[I 2023-11-24 22:30:54,418] Trial 2 finished with value: 0.6857588696628624 and parameters: {'learning_rate': 7.62395715218845e-07, 'max_depth': 7, 'min_child_weight': 10, 'gamma': 0.0019273354395564623, 'lambda': 1.0018294580491717e-08, 'alpha': 1.778271078574009e-05}. Best is trial 1 with value: 0.7636608358426105.
[I 2023-11-24 22:48:50,760] Trial 3 finished with value: 0.6862199242333208 and parameters: {'learning_rate': 1.0629743390554943e-08, 'max_depth': 3, 'min_child_weight': 3, 'gamma': 0.10867336088051248, 'lambda': 0.0012890651176698594, 'alpha': 0.11370809413371795}. Best is trial 1 with value: 0.7636608358426105.
[I 2023-11-24 23:22:40,023] Trial 4 finished with value: 0.6964457514276978 and parameters: {'learning_rate': 1.2251821139884284e-05, 'max_depth': 5, 'min_child_weight': 10, 'gamma': 3.751714874689068e-07, 'lambda': 3.584723157515433e-05, 'alpha': 1.7616903701345546e-05}. Best is trial 1 with value: 0.7636608358426105.
[I 2023-11-25 00:52:54,868] Trial 5 finished with value: 0.8094989552080905 and parameters: {'learning_rate': 0.00366038822429919, 'max_depth': 3, 'min_child_weight': 2, 'gamma': 0.00025356556224159153, 'lambda': 0.007054452837280754, 'alpha': 0.0007792828753438116}. Best is trial 5 with value: 0.8094989552080905.
[I 2023-11-25 00:53:26,098] Trial 6 pruned. Trial was pruned at iteration 0.
[I 2023-11-25 00:55:30,919] Trial 7 pruned. Trial was pruned at iteration 3.
[I 2023-11-25 01:14:40,758] Trial 8 pruned. Trial was pruned at iteration 37.
[I 2023-11-25 01:16:38,461] Trial 9 pruned. Trial was pruned at iteration 3.
[I 2023-11-25 02:24:39,968] Trial 10 pruned. Trial was pruned at iteration 138.
[I 2023-11-25 02:26:37,855] Trial 11 pruned. Trial was pruned at iteration 3.
[I 2023-11-25 03:17:40,494] Trial 12 finished with value: 0.804448752617912 and parameters: {'learning_rate': 0.029431960222358746, 'max_depth': 3, 'min_child_weight': 8, 'gamma': 1.8885177711538692e-08, 'lambda': 3.314625549832013e-06, 'alpha': 1.0699341310851157e-06}. Best is trial 5 with value: 0.8094989552080905.
[I 2023-11-25 03:19:38,240] Trial 13 pruned. Trial was pruned at iteration 3.
[I 2023-11-25 03:21:35,897] Trial 14 pruned. Trial was pruned at iteration 3.
[I 2023-11-25 03:22:05,441] Trial 15 pruned. Trial was pruned at iteration 0.
[I 2023-11-25 04:02:55,485] Trial 16 pruned. Trial was pruned at iteration 83.
[I 2023-11-25 04:04:53,146] Trial 17 pruned. Trial was pruned at iteration 3.
[I 2023-11-25 04:37:37,366] Trial 18 pruned. Trial was pruned at iteration 67.
[I 2023-11-25 05:10:47,346] Trial 19 pruned. Trial was pruned at iteration 67.
[I 2023-11-25 05:12:44,648] Trial 20 pruned. Trial was pruned at iteration 3.
[I 2023-11-25 05:14:41,953] Trial 21 pruned. Trial was pruned at iteration 3.
[I 2023-11-25 05:16:39,506] Trial 22 pruned. Trial was pruned at iteration 3.
[I 2023-11-25 05:18:36,637] Trial 23 pruned. Trial was pruned at iteration 3.
[I 2023-11-25 05:20:33,771] Trial 24 pruned. Trial was pruned at iteration 3.
[I 2023-11-25 05:53:06,183] Trial 25 pruned. Trial was pruned at iteration 67.
[I 2023-11-25 05:55:03,804] Trial 26 pruned. Trial was pruned at iteration 3.
[I 2023-11-25 05:57:01,124] Trial 27 pruned. Trial was pruned at iteration 3.
[I 2023-11-25 05:59:27,885] Trial 28 pruned. Trial was pruned at iteration 4.
[I 2023-11-25 06:18:01,252] Trial 29 pruned. Trial was pruned at iteration 37.
[I 2023-11-25 07:21:19,301] Trial 30 finished with value: 0.8138616199051899 and parameters: {'learning_rate': 0.010658855046678555, 'max_depth': 6, 'min_child_weight': 6, 'gamma': 9.0882838572945e-07, 'lambda': 6.706296737666406e-07, 'alpha': 4.259870611961671e-08}. Best is trial 30 with value: 0.8138616199051899.
[I 2023-11-25 08:47:39,946] Trial 31 finished with value: 0.8148718696187937 and parameters: {'learning_rate': 0.011945985999466299, 'max_depth': 6, 'min_child_weight': 6, 'gamma': 7.102307491026427e-07, 'lambda': 3.7740871032338757e-07, 'alpha': 4.061911937043053e-08}. Best is trial 31 with value: 0.8148718696187937.
[I 2023-11-25 08:49:49,441] Trial 32 pruned. Trial was pruned at iteration 3.
[I 2023-11-25 08:51:58,990] Trial 33 pruned. Trial was pruned at iteration 3.
[I 2023-11-25 09:12:28,820] Trial 34 pruned. Trial was pruned at iteration 37.
[I 2023-11-25 09:14:38,498] Trial 35 pruned. Trial was pruned at iteration 3.
[I 2023-11-25 09:54:26,816] Trial 36 pruned. Trial was pruned at iteration 74.
[I 2023-11-25 10:14:49,727] Trial 37 pruned. Trial was pruned at iteration 37.
[I 2023-11-25 10:16:58,840] Trial 38 pruned. Trial was pruned at iteration 3.
[I 2023-11-25 10:56:08,984] Trial 39 pruned. Trial was pruned at iteration 72.
[I 2023-11-25 11:00:28,035] Trial 40 pruned. Trial was pruned at iteration 7.
[I 2023-11-25 11:02:37,620] Trial 41 pruned. Trial was pruned at iteration 3.
[I 2023-11-25 11:59:26,625] Trial 42 pruned. Trial was pruned at iteration 105.
[I 2023-11-25 12:19:30,900] Trial 43 pruned. Trial was pruned at iteration 37.
[I 2023-11-25 13:15:51,161] Trial 44 pruned. Trial was pruned at iteration 105.
[I 2023-11-25 13:18:00,054] Trial 45 pruned. Trial was pruned at iteration 3.
[I 2023-11-25 13:20:09,329] Trial 46 pruned. Trial was pruned at iteration 3.
[I 2023-11-25 13:22:19,004] Trial 47 pruned. Trial was pruned at iteration 3.
[I 2023-11-25 13:24:28,820] Trial 48 pruned. Trial was pruned at iteration 3.
[I 2023-11-25 13:26:38,770] Trial 49 pruned. Trial was pruned at iteration 3.
Completed hyperparameter tuning with best ndcg@25 = 0.8148718696187937.
Re-running the best trial... params = {'verbosity': 0, 'eval_metric': 'ndcg@25', 'device': 'cuda', 'learning_rate': 0.011945985999466299, 'max_depth': 6, 'min_child_weight': 6, 'gamma': 7.102307491026427e-07, 'lambda': 3.7740871032338757e-07, 'alpha': 4.061911937043053e-08}
