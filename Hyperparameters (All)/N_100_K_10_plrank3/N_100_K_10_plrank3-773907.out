[I 2023-11-24 08:09:15,618] A new study created in memory with name: no-name-a6d8b927-6256-49f4-931c-0dd608058352
[I 2023-11-24 08:29:28,646] Trial 0 finished with value: 0.5965440802461968 and parameters: {'learning_rate': 3.1319171138737175e-07, 'max_depth': 2, 'min_child_weight': 7, 'gamma': 0.010729751880168505, 'lambda': 0.06296312307016198, 'alpha': 0.0007394392365722692}. Best is trial 0 with value: 0.5965440802461968.
[I 2023-11-24 09:05:42,562] Trial 1 finished with value: 0.592618526329771 and parameters: {'learning_rate': 9.75567257517296e-07, 'max_depth': 6, 'min_child_weight': 9, 'gamma': 8.969264748021074e-08, 'lambda': 0.42600639691401987, 'alpha': 0.00013899552118614968}. Best is trial 0 with value: 0.5965440802461968.
[I 2023-11-24 09:39:29,520] Trial 2 finished with value: 0.5937380080103837 and parameters: {'learning_rate': 4.015158222263966e-08, 'max_depth': 4, 'min_child_weight': 6, 'gamma': 0.48286935245103696, 'lambda': 3.88517598759873e-06, 'alpha': 1.7067528214963798e-05}. Best is trial 0 with value: 0.5965440802461968.
[I 2023-11-24 10:18:43,006] Trial 3 finished with value: 0.6052226212906522 and parameters: {'learning_rate': 0.0002486074925276533, 'max_depth': 4, 'min_child_weight': 9, 'gamma': 0.08894076471305294, 'lambda': 7.901314467457086e-08, 'alpha': 1.0725438001551242e-08}. Best is trial 3 with value: 0.6052226212906522.
[I 2023-11-24 11:13:18,157] Trial 4 finished with value: 0.600414964767763 and parameters: {'learning_rate': 4.7325226878879133e-07, 'max_depth': 1, 'min_child_weight': 7, 'gamma': 3.963525983082778e-05, 'lambda': 6.394552537160185e-07, 'alpha': 1.196700832819443e-06}. Best is trial 3 with value: 0.6052226212906522.
[I 2023-11-24 11:19:44,347] Trial 5 pruned. Trial was pruned at iteration 12.
[I 2023-11-24 12:57:39,211] Trial 6 finished with value: 0.7623240803160845 and parameters: {'learning_rate': 0.027018712182022894, 'max_depth': 6, 'min_child_weight': 5, 'gamma': 6.754372661976432e-07, 'lambda': 5.265607469537144e-06, 'alpha': 0.0020943246637493483}. Best is trial 6 with value: 0.7623240803160845.
[I 2023-11-24 13:51:43,364] Trial 7 pruned. Trial was pruned at iteration 110.
[I 2023-11-24 14:11:31,088] Trial 8 pruned. Trial was pruned at iteration 39.
[I 2023-11-24 14:22:55,528] Trial 9 finished with value: 0.5984774389984112 and parameters: {'learning_rate': 7.640494223737553e-08, 'max_depth': 5, 'min_child_weight': 7, 'gamma': 0.02625581009691698, 'lambda': 0.01586743256564208, 'alpha': 0.0012726412292860245}. Best is trial 6 with value: 0.7623240803160845.
/home/jkang1/plrank3.py:106: RuntimeWarning: divide by zero encountered in divide
  cumsum_weight_denom = np.cumsum(rank_weights[:cutoff] / denom_per_rank, axis=1)
/home/jkang1/plrank3.py:108: RuntimeWarning: divide by zero encountered in divide
  cumsum_reward_denom = np.cumsum(cumsum_labels / denom_per_rank, axis=1)
/home/jkang1/plrank3.py:108: RuntimeWarning: invalid value encountered in divide
  cumsum_reward_denom = np.cumsum(cumsum_labels / denom_per_rank, axis=1)
/home/jkang1/plrank3.py:112: RuntimeWarning: invalid value encountered in multiply
  second_part = -exp_scores[None, :] * cumsum_reward_denom[:, -1, None]
/home/jkang1/plrank3.py:114: RuntimeWarning: invalid value encountered in multiply
  labels[relevant_docs][None, :]
/home/jkang1/plrank3.py:113: RuntimeWarning: invalid value encountered in add
  second_part[:, relevant_docs] += (
/home/jkang1/plrank3.py:122: RuntimeWarning: invalid value encountered in multiply
  labels[cutoff_sampled_rankings]
/home/jkang1/plrank3.py:126: RuntimeWarning: invalid value encountered in multiply
  sampled_following_reward = exp_scores[cutoff_sampled_rankings] * cumsum_reward_denom
/home/jkang1/plrank3.py:166: RuntimeWarning: divide by zero encountered in divide
  * np.cumsum(1 / denom_per_rank[:, :-1], axis=1)
/home/jkang1/plrank3.py:165: RuntimeWarning: invalid value encountered in multiply
  - exp_scores[cutoff_sampled_rankings[:, :-1]]
/home/jkang1/plrank3.py:171: RuntimeWarning: divide by zero encountered in divide
  cumsum_denom = np.cumsum(1 / denom_per_rank, axis=1)
/home/jkang1/plrank3.py:172: RuntimeWarning: invalid value encountered in multiply
  sum_prob_per_doc = exp_scores * cumsum_denom[:, -1, None]
/home/jkang1/plrank3.py:174: RuntimeWarning: invalid value encountered in multiply
  exp_scores[cutoff_sampled_rankings] * cumsum_denom
/home/jkang1/plrank3.py:182: RuntimeWarning: divide by zero encountered in divide
  cumsum_weight_denom = np.cumsum(rank_weights[:cutoff] / denom_per_rank, axis=1)
/home/jkang1/plrank3.py:184: RuntimeWarning: divide by zero encountered in divide
  cumsum_reward_denom = np.cumsum(cumsum_labels / denom_per_rank, axis=1)
/home/jkang1/plrank3.py:184: RuntimeWarning: invalid value encountered in divide
  cumsum_reward_denom = np.cumsum(cumsum_labels / denom_per_rank, axis=1)
/home/jkang1/plrank3.py:187: RuntimeWarning: invalid value encountered in multiply
  second_part = -exp_scores[None, :] * cumsum_reward_denom[:, -1, None]
/home/jkang1/plrank3.py:189: RuntimeWarning: invalid value encountered in multiply
  labels[relevant_docs][None, :]
/home/jkang1/plrank3.py:188: RuntimeWarning: invalid value encountered in add
  second_part[:, relevant_docs] += (
/home/jkang1/plrank3.py:197: RuntimeWarning: invalid value encountered in multiply
  labels[cutoff_sampled_rankings]
/home/jkang1/plrank3.py:201: RuntimeWarning: invalid value encountered in multiply
  sampled_following_reward = exp_scores[cutoff_sampled_rankings] * cumsum_reward_denom
/home/jkang1/plrank3.py:208: RuntimeWarning: divide by zero encountered in divide
  rank_weights[:cutoff] / denom_per_rank ** 2, axis=1
/home/jkang1/plrank3.py:211: RuntimeWarning: divide by zero encountered in divide
  cumsum_reward_denom_square = np.cumsum(cumsum_labels / denom_per_rank ** 2, axis=1)
/home/jkang1/plrank3.py:211: RuntimeWarning: invalid value encountered in divide
  cumsum_reward_denom_square = np.cumsum(cumsum_labels / denom_per_rank ** 2, axis=1)
/home/jkang1/plrank3.py:214: RuntimeWarning: invalid value encountered in multiply
  third_part = -exp_scores[None, :] ** 2 * cumsum_reward_denom_square[:, -1, None]
/home/jkang1/plrank3.py:216: RuntimeWarning: invalid value encountered in multiply
  labels[relevant_docs][None, :]
/home/jkang1/plrank3.py:215: RuntimeWarning: invalid value encountered in add
  third_part[:, relevant_docs] += (
/home/jkang1/plrank3.py:224: RuntimeWarning: invalid value encountered in multiply
  labels[cutoff_sampled_rankings]
/home/jkang1/plrank3.py:229: RuntimeWarning: invalid value encountered in multiply
  exp_scores[cutoff_sampled_rankings] ** 2 * cumsum_reward_denom_square
[I 2023-11-24 15:17:52,279] Trial 10 pruned. Trial was pruned at iteration 110.
[I 2023-11-24 16:12:19,911] Trial 11 pruned. Trial was pruned at iteration 110.
[I 2023-11-24 17:05:30,207] Trial 12 pruned. Trial was pruned at iteration 110.
[I 2023-11-24 17:09:20,616] Trial 13 pruned. Trial was pruned at iteration 7.
[I 2023-11-24 18:02:13,861] Trial 14 pruned. Trial was pruned at iteration 110.
[I 2023-11-24 18:06:04,311] Trial 15 pruned. Trial was pruned at iteration 7.
[I 2023-11-24 18:59:12,133] Trial 16 pruned. Trial was pruned at iteration 110.
[I 2023-11-24 19:50:42,372] Trial 17 pruned. Trial was pruned at iteration 110.
[I 2023-11-24 19:54:28,552] Trial 18 pruned. Trial was pruned at iteration 7.
[I 2023-11-24 20:00:34,586] Trial 19 pruned. Trial was pruned at iteration 12.
[I 2023-11-24 20:06:39,951] Trial 20 pruned. Trial was pruned at iteration 12.
[I 2023-11-24 20:12:45,726] Trial 21 pruned. Trial was pruned at iteration 12.
[I 2023-11-24 20:16:31,178] Trial 22 pruned. Trial was pruned at iteration 7.
[I 2023-11-24 20:37:44,171] Trial 23 finished with value: 0.5986835629911554 and parameters: {'learning_rate': 1.402672074807283e-05, 'max_depth': 2, 'min_child_weight': 6, 'gamma': 0.0015219474440742579, 'lambda': 1.3870890366233386e-07, 'alpha': 9.182638015990798e-08}. Best is trial 6 with value: 0.7623240803160845.
[I 2023-11-24 20:40:43,758] Trial 24 pruned. Trial was pruned at iteration 5.
[I 2023-11-24 20:43:43,448] Trial 25 pruned. Trial was pruned at iteration 5.
[I 2023-11-24 20:46:42,610] Trial 26 pruned. Trial was pruned at iteration 5.
[I 2023-11-24 20:49:41,662] Trial 27 pruned. Trial was pruned at iteration 5.
[I 2023-11-24 21:44:41,631] Trial 28 pruned. Trial was pruned at iteration 110.
[I 2023-11-24 21:47:40,646] Trial 29 pruned. Trial was pruned at iteration 5.
[I 2023-11-24 21:50:39,753] Trial 30 pruned. Trial was pruned at iteration 5.
[I 2023-11-24 21:57:08,288] Trial 31 pruned. Trial was pruned at iteration 12.
[I 2023-11-24 22:00:07,744] Trial 32 pruned. Trial was pruned at iteration 5.
[I 2023-11-24 22:03:07,176] Trial 33 pruned. Trial was pruned at iteration 5.
[I 2023-11-24 22:06:06,477] Trial 34 pruned. Trial was pruned at iteration 5.
[I 2023-11-24 22:12:34,562] Trial 35 pruned. Trial was pruned at iteration 12.
[I 2023-11-24 22:26:30,580] Trial 36 finished with value: 0.6010341047389997 and parameters: {'learning_rate': 0.00016654041693154565, 'max_depth': 2, 'min_child_weight': 5, 'gamma': 0.00025928789565698394, 'lambda': 2.8723303469894806e-08, 'alpha': 1.2329509292312189e-05}. Best is trial 6 with value: 0.7623240803160845.
[I 2023-11-24 22:30:29,781] Trial 37 pruned. Trial was pruned at iteration 7.
[I 2023-11-24 23:24:12,137] Trial 38 pruned. Trial was pruned at iteration 110.
[I 2023-11-24 23:28:04,328] Trial 39 pruned. Trial was pruned at iteration 7.
[I 2023-11-24 23:30:58,523] Trial 40 pruned. Trial was pruned at iteration 5.
[I 2023-11-24 23:34:21,519] Trial 41 pruned. Trial was pruned at iteration 6.
[I 2023-11-24 23:38:13,133] Trial 42 pruned. Trial was pruned at iteration 7.
[I 2023-11-25 00:31:18,608] Trial 43 pruned. Trial was pruned at iteration 110.
[I 2023-11-25 00:34:41,128] Trial 44 pruned. Trial was pruned at iteration 6.
[I 2023-11-25 00:37:34,458] Trial 45 pruned. Trial was pruned at iteration 5.
[I 2023-11-25 00:40:57,075] Trial 46 pruned. Trial was pruned at iteration 6.
[I 2023-11-25 00:44:48,617] Trial 47 pruned. Trial was pruned at iteration 7.
[I 2023-11-25 00:47:42,419] Trial 48 pruned. Trial was pruned at iteration 5.
[I 2023-11-25 01:05:05,314] Trial 49 finished with value: 0.6009494194916649 and parameters: {'learning_rate': 6.2118759678377956e-06, 'max_depth': 7, 'min_child_weight': 3, 'gamma': 0.0038176918864692494, 'lambda': 3.07895412136231e-08, 'alpha': 0.0009830373336004582}. Best is trial 6 with value: 0.7623240803160845.
Completed hyperparameter tuning with best ndcg@10 = 0.7623240803160845.
Re-running the best trial... params = {'verbosity': 0, 'eval_metric': 'ndcg@10', 'device': 'cuda', 'learning_rate': 0.027018712182022894, 'max_depth': 6, 'min_child_weight': 5, 'gamma': 6.754372661976432e-07, 'lambda': 5.265607469537144e-06, 'alpha': 0.0020943246637493483}
