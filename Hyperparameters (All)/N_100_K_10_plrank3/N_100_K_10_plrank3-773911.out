[I 2023-11-24 08:09:15,652] A new study created in memory with name: no-name-15091ee2-4a06-41e5-b518-8e6cdd4334b8
/home/jkang1/plrank3.py:106: RuntimeWarning: divide by zero encountered in divide
  cumsum_weight_denom = np.cumsum(rank_weights[:cutoff] / denom_per_rank, axis=1)
/home/jkang1/plrank3.py:108: RuntimeWarning: divide by zero encountered in divide
  cumsum_reward_denom = np.cumsum(cumsum_labels / denom_per_rank, axis=1)
/home/jkang1/plrank3.py:108: RuntimeWarning: invalid value encountered in divide
  cumsum_reward_denom = np.cumsum(cumsum_labels / denom_per_rank, axis=1)
/home/jkang1/plrank3.py:112: RuntimeWarning: invalid value encountered in multiply
  second_part = -exp_scores[None, :] * cumsum_reward_denom[:, -1, None]
/home/jkang1/plrank3.py:114: RuntimeWarning: invalid value encountered in multiply
  labels[relevant_docs][None, :]
/home/jkang1/plrank3.py:113: RuntimeWarning: invalid value encountered in add
  second_part[:, relevant_docs] += (
/home/jkang1/plrank3.py:122: RuntimeWarning: invalid value encountered in multiply
  labels[cutoff_sampled_rankings]
/home/jkang1/plrank3.py:126: RuntimeWarning: invalid value encountered in multiply
  sampled_following_reward = exp_scores[cutoff_sampled_rankings] * cumsum_reward_denom
/home/jkang1/plrank3.py:166: RuntimeWarning: divide by zero encountered in divide
  * np.cumsum(1 / denom_per_rank[:, :-1], axis=1)
/home/jkang1/plrank3.py:165: RuntimeWarning: invalid value encountered in multiply
  - exp_scores[cutoff_sampled_rankings[:, :-1]]
/home/jkang1/plrank3.py:171: RuntimeWarning: divide by zero encountered in divide
  cumsum_denom = np.cumsum(1 / denom_per_rank, axis=1)
/home/jkang1/plrank3.py:172: RuntimeWarning: invalid value encountered in multiply
  sum_prob_per_doc = exp_scores * cumsum_denom[:, -1, None]
/home/jkang1/plrank3.py:174: RuntimeWarning: invalid value encountered in multiply
  exp_scores[cutoff_sampled_rankings] * cumsum_denom
/home/jkang1/plrank3.py:182: RuntimeWarning: divide by zero encountered in divide
  cumsum_weight_denom = np.cumsum(rank_weights[:cutoff] / denom_per_rank, axis=1)
/home/jkang1/plrank3.py:184: RuntimeWarning: divide by zero encountered in divide
  cumsum_reward_denom = np.cumsum(cumsum_labels / denom_per_rank, axis=1)
/home/jkang1/plrank3.py:184: RuntimeWarning: invalid value encountered in divide
  cumsum_reward_denom = np.cumsum(cumsum_labels / denom_per_rank, axis=1)
/home/jkang1/plrank3.py:187: RuntimeWarning: invalid value encountered in multiply
  second_part = -exp_scores[None, :] * cumsum_reward_denom[:, -1, None]
/home/jkang1/plrank3.py:189: RuntimeWarning: invalid value encountered in multiply
  labels[relevant_docs][None, :]
/home/jkang1/plrank3.py:188: RuntimeWarning: invalid value encountered in add
  second_part[:, relevant_docs] += (
/home/jkang1/plrank3.py:197: RuntimeWarning: invalid value encountered in multiply
  labels[cutoff_sampled_rankings]
/home/jkang1/plrank3.py:201: RuntimeWarning: invalid value encountered in multiply
  sampled_following_reward = exp_scores[cutoff_sampled_rankings] * cumsum_reward_denom
/home/jkang1/plrank3.py:208: RuntimeWarning: divide by zero encountered in divide
  rank_weights[:cutoff] / denom_per_rank ** 2, axis=1
/home/jkang1/plrank3.py:211: RuntimeWarning: divide by zero encountered in divide
  cumsum_reward_denom_square = np.cumsum(cumsum_labels / denom_per_rank ** 2, axis=1)
/home/jkang1/plrank3.py:211: RuntimeWarning: invalid value encountered in divide
  cumsum_reward_denom_square = np.cumsum(cumsum_labels / denom_per_rank ** 2, axis=1)
/home/jkang1/plrank3.py:214: RuntimeWarning: invalid value encountered in multiply
  third_part = -exp_scores[None, :] ** 2 * cumsum_reward_denom_square[:, -1, None]
/home/jkang1/plrank3.py:216: RuntimeWarning: invalid value encountered in multiply
  labels[relevant_docs][None, :]
/home/jkang1/plrank3.py:215: RuntimeWarning: invalid value encountered in add
  third_part[:, relevant_docs] += (
/home/jkang1/plrank3.py:224: RuntimeWarning: invalid value encountered in multiply
  labels[cutoff_sampled_rankings]
/home/jkang1/plrank3.py:229: RuntimeWarning: invalid value encountered in multiply
  exp_scores[cutoff_sampled_rankings] ** 2 * cumsum_reward_denom_square
[I 2023-11-24 09:46:13,768] Trial 0 finished with value: 0.6827605862164423 and parameters: {'learning_rate': 0.8287540279354078, 'max_depth': 7, 'min_child_weight': 4, 'gamma': 4.779443428401678e-08, 'lambda': 0.0017895014762492193, 'alpha': 0.0012903250968753417}. Best is trial 0 with value: 0.6827605862164423.
[I 2023-11-24 11:24:03,333] Trial 1 finished with value: 0.7399804835669798 and parameters: {'learning_rate': 0.0004976402931152472, 'max_depth': 5, 'min_child_weight': 2, 'gamma': 8.236024317122211e-08, 'lambda': 0.0038976598440866664, 'alpha': 2.3661866429665687e-06}. Best is trial 1 with value: 0.7399804835669798.
[I 2023-11-24 12:59:43,670] Trial 2 finished with value: 0.7553602975238856 and parameters: {'learning_rate': 0.12680701685465412, 'max_depth': 5, 'min_child_weight': 8, 'gamma': 1.395466241821523e-08, 'lambda': 2.1096242104275295e-07, 'alpha': 1.0309664924473037e-06}. Best is trial 2 with value: 0.7553602975238856.
[I 2023-11-24 13:44:16,881] Trial 3 finished with value: 0.722430613010778 and parameters: {'learning_rate': 0.0014197177050374913, 'max_depth': 2, 'min_child_weight': 5, 'gamma': 0.00011829884101512935, 'lambda': 0.053593436497907536, 'alpha': 0.04146092684504989}. Best is trial 2 with value: 0.7553602975238856.
[I 2023-11-24 15:22:04,206] Trial 4 finished with value: 0.7330453777256282 and parameters: {'learning_rate': 0.0007576951012229033, 'max_depth': 3, 'min_child_weight': 2, 'gamma': 0.015876977421487744, 'lambda': 0.000783686971364653, 'alpha': 2.4292000522155184e-06}. Best is trial 2 with value: 0.7553602975238856.
[I 2023-11-24 15:24:02,233] Trial 5 pruned. Trial was pruned at iteration 3.
[I 2023-11-24 15:26:00,150] Trial 6 pruned. Trial was pruned at iteration 3.
[I 2023-11-24 15:27:57,902] Trial 7 pruned. Trial was pruned at iteration 3.
[I 2023-11-24 15:29:55,630] Trial 8 pruned. Trial was pruned at iteration 3.
[I 2023-11-24 15:31:53,205] Trial 9 pruned. Trial was pruned at iteration 3.
[I 2023-11-24 15:33:51,012] Trial 10 pruned. Trial was pruned at iteration 3.
[I 2023-11-24 15:35:48,723] Trial 11 pruned. Trial was pruned at iteration 3.
[I 2023-11-24 15:37:46,110] Trial 12 pruned. Trial was pruned at iteration 3.
[I 2023-11-24 15:39:43,606] Trial 13 pruned. Trial was pruned at iteration 3.
[I 2023-11-24 15:40:13,028] Trial 14 pruned. Trial was pruned at iteration 0.
[I 2023-11-24 15:42:10,755] Trial 15 pruned. Trial was pruned at iteration 3.
[I 2023-11-24 17:15:39,640] Trial 16 finished with value: 0.7600502641912067 and parameters: {'learning_rate': 0.05147754678192803, 'max_depth': 4, 'min_child_weight': 6, 'gamma': 3.7388927733594004e-07, 'lambda': 1.166058214160473e-08, 'alpha': 3.4320329700534383e-06}. Best is trial 16 with value: 0.7600502641912067.
[I 2023-11-24 17:18:02,278] Trial 17 pruned. Trial was pruned at iteration 4.
[I 2023-11-24 17:30:52,146] Trial 18 pruned. Trial was pruned at iteration 26.
[I 2023-11-24 17:32:46,306] Trial 19 pruned. Trial was pruned at iteration 3.
[I 2023-11-24 17:33:43,506] Trial 20 pruned. Trial was pruned at iteration 1.
[I 2023-11-24 19:07:05,297] Trial 21 finished with value: 0.7539143492791403 and parameters: {'learning_rate': 0.009231946375821655, 'max_depth': 5, 'min_child_weight': 3, 'gamma': 5.5805301109951715e-08, 'lambda': 4.2225160568806024e-08, 'alpha': 1.8865197963317653e-06}. Best is trial 16 with value: 0.7600502641912067.
[I 2023-11-24 20:40:04,882] Trial 22 finished with value: 0.7547095597459254 and parameters: {'learning_rate': 0.008990151568569003, 'max_depth': 4, 'min_child_weight': 5, 'gamma': 6.678204173933963e-08, 'lambda': 4.877646238442304e-08, 'alpha': 1.7307523091061092e-06}. Best is trial 16 with value: 0.7600502641912067.
[I 2023-11-24 20:41:03,831] Trial 23 pruned. Trial was pruned at iteration 1.
[I 2023-11-24 21:57:43,825] Trial 24 finished with value: 0.7550163195683918 and parameters: {'learning_rate': 0.0345618712280866, 'max_depth': 4, 'min_child_weight': 6, 'gamma': 3.7312733105245196e-08, 'lambda': 2.2921514131907396e-07, 'alpha': 1.387870192169429e-06}. Best is trial 16 with value: 0.7600502641912067.
[I 2023-11-24 21:58:42,790] Trial 25 pruned. Trial was pruned at iteration 1.
[I 2023-11-24 21:59:41,661] Trial 26 pruned. Trial was pruned at iteration 1.
[I 2023-11-24 22:00:40,643] Trial 27 pruned. Trial was pruned at iteration 1.
[I 2023-11-24 22:02:09,157] Trial 28 pruned. Trial was pruned at iteration 2.
[I 2023-11-24 22:03:37,552] Trial 29 pruned. Trial was pruned at iteration 2.
[I 2023-11-24 22:04:36,410] Trial 30 pruned. Trial was pruned at iteration 1.
[I 2023-11-24 22:05:35,233] Trial 31 pruned. Trial was pruned at iteration 1.
[I 2023-11-24 22:06:34,065] Trial 32 pruned. Trial was pruned at iteration 1.
[I 2023-11-24 22:07:32,822] Trial 33 pruned. Trial was pruned at iteration 1.
[I 2023-11-24 22:08:31,598] Trial 34 pruned. Trial was pruned at iteration 1.
[I 2023-11-24 22:09:30,607] Trial 35 pruned. Trial was pruned at iteration 1.
[I 2023-11-24 22:10:29,606] Trial 36 pruned. Trial was pruned at iteration 1.
[I 2023-11-24 22:11:28,601] Trial 37 pruned. Trial was pruned at iteration 1.
[I 2023-11-24 22:12:27,497] Trial 38 pruned. Trial was pruned at iteration 1.
[I 2023-11-24 22:13:26,273] Trial 39 pruned. Trial was pruned at iteration 1.
[I 2023-11-24 22:26:59,846] Trial 40 pruned. Trial was pruned at iteration 27.
[I 2023-11-24 22:27:58,681] Trial 41 pruned. Trial was pruned at iteration 1.
[I 2023-11-24 22:28:57,550] Trial 42 pruned. Trial was pruned at iteration 1.
[I 2023-11-24 22:30:25,669] Trial 43 pruned. Trial was pruned at iteration 2.
[I 2023-11-24 22:31:24,541] Trial 44 pruned. Trial was pruned at iteration 1.
[I 2023-11-24 22:33:22,672] Trial 45 pruned. Trial was pruned at iteration 3.
[I 2023-11-24 22:34:21,441] Trial 46 pruned. Trial was pruned at iteration 1.
[I 2023-11-24 22:36:18,820] Trial 47 pruned. Trial was pruned at iteration 3.
[I 2023-11-24 22:37:17,504] Trial 48 pruned. Trial was pruned at iteration 1.
[I 2023-11-24 22:38:16,474] Trial 49 pruned. Trial was pruned at iteration 1.
Completed hyperparameter tuning with best ndcg@10 = 0.7600502641912067.
Re-running the best trial... params = {'verbosity': 0, 'eval_metric': 'ndcg@10', 'device': 'cuda', 'learning_rate': 0.05147754678192803, 'max_depth': 4, 'min_child_weight': 6, 'gamma': 3.7388927733594004e-07, 'lambda': 1.166058214160473e-08, 'alpha': 3.4320329700534383e-06}
